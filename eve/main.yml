---
version: "0.2"

branches:
  user/*, feature/*, improvement/*, bugfix/*, w/*, q/*, hotfix/*, dependabot/*:
    stage: pre-merge

models:
  # --- Re-usable steps (no parameters) ---
  - Git: &git_pull
      name: git pull
      repourl: "%(prop:git_reference)s"
      method: clobber
      retryFetch: true
      haltOnFailure: true
  - ShellCommand: &setup_cache
      name: Setup proxy cache
      command: >
          curl -s http://proxy-cache/setup.sh | sudo sh &&
          . /usr/local/bin/use_scality_proxy_cache
      haltOnFailure: true
  - ShellCommand: &wait_for_docker
      name: Wait for Docker daemon to be ready
      command: |
        bash -c '
        for i in {1..150}
        do
          docker info &> /dev/null && exit
          sleep 2
        done
        echo "Could not reach Docker daemon from buildbot worker" >&2
        exit 1'
      haltOnFailure: true
  - ShellCommand: &build_all
      name: Build everything
      env:
        PYTHON_SYS: python3.6
      # There are 3 CPUs available for Docker, and 1 for `doit` in the Pod.
      # Given the network IO-bound nature of some of the build steps, and
      # most build steps running in Docker, set concurrency to 4.
      command: ./doit.sh -n 4
      usePTY: true
      haltOnFailure: true
  - ShellCommand: &ssh_ip_setup
      name: Report IP and install SSH keys
      command: >
        ip a &&
        mkdir -p ~/.ssh &&
        echo "%(secret:ssh_pub_keys)s" >> ~/.ssh/authorized_keys
  - ShellCommand: &check_iso_checksum
      name: Check image with checksum
      command: sha256sum -c SHA256SUM
      haltOnFailure: true
  - Upload: &upload_artifacts
      name: Upload artifacts
      source: artifacts
  - Upload: &upload_report_artifacts
      name: Upload sosreport logs to artifacts
      source: sosreport
  - ShellCommand: &collect_sosreport
      name: Collect logs using sosreport
      command: >
        sudo sosreport --all-logs
        -o metalk8s -kmetalk8s.podlogs=True
        -o containerd -kcontainerd.all=True -kcontainerd.logs=True
        --batch --tmp-dir /var/tmp &&
        sudo chown eve:eve /var/tmp/sosreport*
  - ShellCommand: &wait_debug
      name: Debug step - wait befor allowing resource destruction
      timeout: 3600
      command: sleep 3600
      doStepIf: false
      alwaysRun: true

  # --- Re-usable steps (with parameters) ---
  - SetPropertyFromCommand: &set_version_prop
      name: Set version as property from built artifacts
      property: metalk8s_version
      env:
        BASE_URL: "%(prop:artifacts_private_url)s"
      command: >
        bash -c '
        . <(curl -s "${BASE_URL}/product.txt") &&
        echo $VERSION'
  - ShellCommand: &copy_artifacts
      name: Put the artifacts to upload in a separate directory
      env: &_env_copy_artifacts
        DEST_DIR: "artifacts"
        ARTIFACTS: >-
          _build/metalk8s.iso
          _build/SHA256SUM
          _build/root/product.txt
      command: |
        bash -c '
        mkdir "${DEST_DIR}" -p
        for artifact in ${ARTIFACTS}; do
          cp "$artifact" "${DEST_DIR}"
        done'
      haltOnFailure: true
  - ShellCommand: &copy_report_artifacts
      name: Put the sosreport logs to upload in a separate directory
      env:
        DEST_DIR: sosreport/sosreport
      command: mkdir -p "${DEST_DIR}" && cp /var/tmp/sosreport* "${DEST_DIR}"
      alwaysRun: true
  - ShellCommand: &retrieve_iso
      name: Retrieve ISO image
      env:
        BASE_URL: "%(prop:artifacts_private_url)s"
        DEST_DIR: "."
      command: >
        curl -s -XGET -o "${DEST_DIR}/metalk8s.iso" "${BASE_URL}/metalk8s.iso"
      haltOnFailure: true
      # Increase default timeout for ISOs, as artifacts may be too slow
      timeout: 2400
  - ShellCommand: &retrieve_iso_checksum
      <<: *retrieve_iso
      name: Retrieve ISO image checksum
      command: >
        curl -s -XGET -o "${DEST_DIR}/SHA256SUM" "${BASE_URL}/SHA256SUM"
  - ShellCommand: &create_mountpoint
      name: Create mountpoint
      env:
        PRODUCT_VERSION: "%(prop:metalk8s_version)s"
      command: sudo mkdir -p "/srv/scality/metalk8s-${PRODUCT_VERSION}"
  - ShellCommand: &mount_iso
      name: Mount ISO image
      env:
        ISO_PATH: metalk8s.iso
        PRODUCT_VERSION: "%(prop:metalk8s_version)s"
      command: >
        sudo mount -o loop "${ISO_PATH}"
        "/srv/scality/metalk8s-${PRODUCT_VERSION}"
  - ShellCommand: &bootstrap_config
      name: Create bootstrap configuration file
      env:
        PRODUCT_VERSION: "%(prop:metalk8s_version)s"
      command: |
        sudo bash << EOF
        mkdir -p /etc/metalk8s
        cat > /etc/metalk8s/bootstrap.yaml << END
        apiVersion: metalk8s.scality.com/v1alpha2
        kind: BootstrapConfiguration
        networks:
          controlPlane: 10.100.0.0/16
          workloadPlane: 10.100.0.0/16
        ca:
          minion: $(hostname)
        apiServer:
          host: $(ip route get 10.100.0.0 | awk '/10.100.0.0/{ print $6 }')
        archives:
          - "/srv/scality/metalk8s-${PRODUCT_VERSION}"
        END
        EOF
      haltOnFailure: true
  - ShellCommand: &run_bootstrap
      name: Start the bootstrap process
      env:
        PRODUCT_VERSION: "%(prop:metalk8s_version)s"
      command: >
        sudo bash
        "/srv/scality/metalk8s-${PRODUCT_VERSION}/bootstrap.sh"
        --verbose
      haltOnFailure: true
  - ShellCommand: &local_tests
      name: Run tests locally
      env: &_env_local_tests
        BRANCH: "%(prop:branch)s"
        ISO_MOUNTPOINT: "/srv/scality/metalk8s-%(prop:metalk8s_version)s"
        PYTEST_FILTERS: "post and ci and not multinodes"
      command: >
        git checkout "${BRANCH}" &&
        tox -e tests-local -- -m "${PYTEST_FILTERS}"
      haltOnFailure: true
  - ShellCommand: &bastion_tests
      name: Run tests on Bastion
      env: &_env_bastion_tests
        SSH_CONFIG_FILE: "/home/centos/ssh_config"
        ISO_MOUNTPOINT: "/var/tmp/metalk8s"
        TEST_HOSTS_LIST: "bootstrap"
        PYTEST_FILTERS: "post and ci"
      command: >
        ssh -F ssh_config bastion --
        "cd metalk8s &&
        export SSH_CONFIG_FILE=\"${SSH_CONFIG_FILE}\" &&
        export ISO_MOUNTPOINT=\"${ISO_MOUNTPOINT}\" &&
        export TEST_HOSTS_LIST=\"${TEST_HOSTS_LIST}\" &&
        tox -e tests -- -m \"${PYTEST_FILTERS}\""
      workdir: build/eve/workers/openstack-multiple-nodes/terraform/
      haltOnFailure: true

stages:
  pre-merge:
    worker:
      type: local
    steps:
      - TriggerStages:
          name: Trigger build, docs and lint stages simultaneously
          stage_names:
            - build
            - docs
            - lint
          haltOnFailure: true
      - SetPropertyFromCommand: *set_version_prop
      - TriggerStages:
          name: Trigger single-node and multiple-nodes steps with built ISO
          stage_names:
            - single-node
            - multiple-nodes

  build:
    worker: &build_worker
      type: kube_pod
      path: eve/workers/pod-builder/pod.yaml
      images:
        docker-builder: eve/workers/pod-builder
    steps:
      - ShellCommand: *wait_for_docker
      - Git: *git_pull
      - ShellCommand: *setup_cache
      - ShellCommand: *build_all
      - ShellCommand:
          <<: *copy_artifacts
          env:
            <<: *_env_copy_artifacts
            ARTIFACTS: >-
              build.log
              _build/metalk8s.iso
              _build/SHA256SUM
              _build/root/product.txt
      - Upload: *upload_artifacts

  docs:
    worker:
      type: kube_pod
      path: eve/workers/pod-docs-builder/pod.yaml
      images:
        doc-builder:
          context: '.'
          dockerfile: docs/Dockerfile
    steps:
      - Git: *git_pull
      - ShellCommand: *setup_cache
      - ShellCommand:
          name: Build documentation
          env:
            # Fake that we are building in a ReadTheDocs environment
            READTHEDOCS: 'True'
          command: tox --workdir /tmp/tox -e docs -- html latexpdf
          haltOnFailure: true
      - Upload:
          name: Upload documentation artifacts
          source: docs/_build
          urls:
            - ['docs/\1', '*']

  lint:
    worker:
      type: kube_pod
      path: eve/workers/pod-linter/pod.yaml
      images:
        docker-linter: eve/workers/pod-linter
    steps:
      - Git: *git_pull
      - ShellCommand: *setup_cache
      - ShellCommand:
          name: Run all linting targets
          command: ./doit.sh lint
          usePTY: true
          haltOnFailure: false

  single-node:
    worker:
      type: openstack
      image: CentOS-7-x86_64-GenericCloud-1809.qcow2
      flavor: m1.large
      path: eve/workers/openstack-single-node
    steps:
      - Git: *git_pull
      - ShellCommand: *setup_cache
      - ShellCommand: *ssh_ip_setup
      # --- Retrieve ISO ---
      - ShellCommand: *retrieve_iso
      - ShellCommand: *retrieve_iso_checksum
      - ShellCommand: *check_iso_checksum
      # --- Prepare for Bootstrap ---
      - ShellCommand: *create_mountpoint
      - ShellCommand: *mount_iso
      - ShellCommand: *bootstrap_config
      # --- Install ---
      - ShellCommand: *run_bootstrap
      # --- Test ---
      - ShellCommand: &fast_tests
          <<: *local_tests
          name: Run fast tests locally
          env: &_env_fast_tests
            <<: *_env_local_tests
            PYTEST_FILTERS: "post and ci and not multinodes and not slow"
      - ShellCommand:
          <<: *local_tests
          name: Run slow tests locally
          env:
            <<: *_env_local_tests
            PYTEST_FILTERS: "post and ci and not multinodes and slow"
      # --- Collect logs ---
      - ShellCommand: *collect_sosreport
      - ShellCommand:
          <<: *copy_report_artifacts
          env:
            DEST_DIR: sosreport/sosreport/single-node-downgrade
      - Upload: *upload_report_artifacts
      - ShellCommand: *wait_debug

  multiple-nodes:
    worker:
      <<: *single_node_worker
      flavor: m1.medium
      path: eve/workers/openstack-multiple-nodes
    steps:
      - Git: *git_pull
      - ShellCommand: *setup_cache
      - ShellCommand: *ssh_ip_setup
      - ShellCommand: *retrieve_iso
      - ShellCommand: *retrieve_iso_checksum
      - ShellCommand: *check_iso_checksum
      - ShellCommand:
          name: Check if unzip and curl are installed
          command: |-
            if ! unzip -h 2&> /dev/null; then
              echo "aborting - unzip not installed and required" >&2
              exit 1
            fi
            if ! curl -h 2&> /dev/null; then
              echo "aborting - curl not installed and required" >&2
              exit 1
            fi
          haltOnFailure: true
      - ShellCommand:
          name: Download and install terraform
          env:
            TF_VERSION: "0.12.3"
          command: >
            TF_URL="https://releases.hashicorp.com/terraform/${TF_VERSION}/";
            TF_FILE="terraform_${TF_VERSION}_linux_amd64.zip";
            curl --retry 5 -O "${TF_URL}${TF_FILE}" &&
            sudo unzip "${TF_FILE}" -d /usr/local/sbin/ &&
            rm -f "${TF_FILE}"
          haltOnFailure: true
      - ShellCommand:
          name: Check that terraform was installed
          command: |-
            if ! terraform --version 2&> /dev/null; then
              echo "aborting - terraform not installed and required" >&2
              exit 1
            fi
          haltOnFailure: true
      - ShellCommand:
          name: Init terraform
          command: |-
            for _ in $(seq 1 12); do
              if terraform init; then
                break
              else
                rm -rf .terraform/
                sleep 5
              fi
            done;
          workdir: build/eve/workers/openstack-multiple-nodes/terraform/
          haltOnFailure: true
      - ShellCommand:
          name: Validate terraform definition
          command: terraform validate
          workdir: build/eve/workers/openstack-multiple-nodes/terraform/
          haltOnFailure: true
      - ShellCommand:
          name: Spawn openstack virtual infra
          command: terraform apply -auto-approve
          workdir: build/eve/workers/openstack-multiple-nodes/terraform/
          env: &_env_terraform
            OS_AUTH_URL: "%(secret:scality_cloud_auth_url)s"
            OS_REGION_NAME: "%(secret:scality_cloud_region)s"
            OS_USERNAME: "%(secret:scality_cloud_username)s"
            OS_PASSWORD: "%(secret:scality_cloud_password)s"
            OS_TENANT_NAME: "%(secret:scality_cloud_tenant_name)s"
            # FIXME: this makes hostnames too long
            # TF_VAR_worker_uuid: "%(prop:worker_uuid)s"
            TF_VAR_nodes_count: "2"
          haltOnFailure: true
      - ShellCommand:
          name: Check SSH config for bootstrap node
          command: |-
            if [ ! -f ssh_config ]; then
              echo "Missing SSH config file" >&2
              exit 1
            fi
            for _ in $(seq 1 12); do
              sleep 5
              ssh -F ssh_config bootstrap id && break
            done;
          workdir: build/eve/workers/openstack-multiple-nodes/terraform/
          haltOnFailure: true
      - ShellCommand:
          # FIXME: find a way to share bastion public key to all spawned
          # instances from Terraform
          name: Send bastion public key to nodes
          command: >
            scp -F ssh_config -3 bastion:.ssh/bastion.pub bootstrap:.ssh/ &&
            ssh -F ssh_config bootstrap
            "cat .ssh/bastion.pub >> .ssh/authorized_keys" &&
            scp -F ssh_config -3 bastion:.ssh/bastion.pub node1:.ssh/ &&
            ssh -F ssh_config node1
            "cat .ssh/bastion.pub >> .ssh/authorized_keys"
          workdir: build/eve/workers/openstack-multiple-nodes/terraform/
      - ShellCommand:
          # FIXME: find a cleaner way with Terraform.
          name: Send bastion private key to bootstrap
          command: >
              ssh -F ssh_config bootstrap "sudo mkdir -p /etc/metalk8s/pki/" &&
              scp -F ssh_config -3 bastion:.ssh/bastion bootstrap:./         &&
              ssh -F ssh_config bootstrap "sudo cp bastion /etc/metalk8s/pki/"
          workdir: build/eve/workers/openstack-multiple-nodes/terraform/
      - ShellCommand:
          name: Copy ISO to bootstrap node
          command: >
            scp -F ssh_config ../../../../metalk8s.iso bootstrap:
          workdir: build/eve/workers/openstack-multiple-nodes/terraform/
          haltOnFailure: true
      - ShellCommand:
          name: Create mountpoint in bootstrap node
          command: >
            ssh -F ssh_config bootstrap
            sudo mkdir -p /var/tmp/metalk8s
          workdir: build/eve/workers/openstack-multiple-nodes/terraform/
          haltOnFailure: true
      - ShellCommand:
          name: Mount ISO image in bootstrap node
          command: >
            ssh -F ssh_config bootstrap
            sudo mount -o loop metalk8s.iso /var/tmp/metalk8s
          workdir: build/eve/workers/openstack-multiple-nodes/terraform/
          haltOnFailure: true
      - ShellCommand:
          name: Start the bootstrap process in bootstrap node
          command: >
            ssh -F ssh_config bootstrap
            sudo bash
            /var/tmp/metalk8s/bootstrap.sh --verbose
          workdir: build/eve/workers/openstack-multiple-nodes/terraform/
          haltOnFailure: true
      - ShellCommand:
          name: Install kubectl on the boostrap node
          command: >
            ssh -F ssh_config bootstrap
            sudo yum install -y kubectl --disablerepo=*
            --enablerepo=metalk8s-kubernetes
          workdir: build/eve/workers/openstack-multiple-nodes/terraform/
      - ShellCommand:
          name: Enable IPIP
          env:
            SSH_CONFIG: >-
              eve/workers/openstack-multiple-nodes/terraform/ssh_config
          command: >
            ssh -F $SSH_CONFIG bootstrap
            'bash /home/centos/scripts/enable_ipip.sh'
      - ShellCommand:
          # FIXME: should find a cleaner way to do this (git clone may be
          # cumbersome, unless we assume the repo is public and don't use
          # authentication)
          name: Copy test sources to the bastion
          env:
            SSH_CONFIG: >-
              eve/workers/openstack-multiple-nodes/terraform/ssh_config
          command: >
            tar cfp - tox.ini VERSION tests/ buildchain/buildchain/versions.py
            | ssh -F $SSH_CONFIG bastion '(mkdir metalk8s; cd "$_"; tar xf -)'
      - ShellCommand:
          <<: *bastion_tests
          name: Run installation scenarii on the bastion
          env:
            <<: *_env_bastion_tests
            PYTEST_FILTERS: "install and ci and multinodes"
      - ShellCommand:
          <<: *bastion_tests
          name: Run fast tests on the bastion
          env:
            <<: *_env_bastion_tests
            PYTEST_FILTERS: "post and ci and not slow"
      - ShellCommand:
          <<: *bastion_tests
          name: Run slow tests on the bastion
          env:
            <<: *_env_bastion_tests
            PYTEST_FILTERS: "post and ci and slow"
      - ShellCommand:
          name: Generate sosreport on every machine
          env:
            SSH_CONFIG: >-
              eve/workers/openstack-multiple-nodes/terraform/ssh_config
          command: >
            for host in bootstrap node1; do
              ssh -F $SSH_CONFIG $host \
              "sudo sosreport --all-logs -o metalk8s -kmetalk8s.podlogs=True\
              -o containerd -kcontainerd.all=True -kcontainerd.logs=True\
              --batch --tmp-dir /var/tmp && \
              sudo chown centos:centos /var/tmp/sosreport*"
            done
          alwaysRun: true
      - ShellCommand:
          name: Download every sosreport to the bastion
          env:
            SSH_CONFIG: >-
              eve/workers/openstack-multiple-nodes/terraform/ssh_config
          command: >
            mkdir -p sosreport/sosreport/multi-node &&
            for host in bootstrap node1; do
              scp -F $SSH_CONFIG \
              $host:/var/tmp/sosreport-* \
              sosreport/sosreport/multi-node/$host-sosreport.tar.xz
            done
          alwaysRun: true
      - Upload: *upload_report_artifacts
      - ShellCommand:
          <<: *wait_debug
          timeout: 14400
          command: sleep 14400
      - ShellCommand:
          name: Destroy openstack virtual infra
          command: |-
            for _ in $(seq 1 3); do
               terraform destroy -auto-approve && break
            done;
          workdir: build/eve/workers/openstack-multiple-nodes/terraform/
          env: *_env_terraform
          alwaysRun: true
          sigtermTime: 600
