kubeTargetVersionOverride: 1.15.3

commonLabels:
  # This needs to remain 'Tiller' for the render script to work properly
  #heritage: 'metalk8s'
  app.kubernetes.io/part-of: 'metalk8s'
  app.kubernetes.io/managed-by: 'metalk8s'

alertmanager:
  alertmanagerSpec:
    image:
      repository: '__image__(alertmanager)'

    nodeSelector:
      node-role.kubernetes.io/infra: ''

    podAntiAffinity: 'soft'

    tolerations:
      - key: 'node-role.kubernetes.io/bootstrap'
        operator: 'Exists'
        effect: 'NoSchedule'
      - key: 'node-role.kubernetes.io/infra'
        operator: 'Exists'
        effect: 'NoSchedule'

    replicas: '__var__(alertmanager.spec.deployment.replicas)'

    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: metalk8s-prometheus
          accessModes: ['ReadWriteOnce']
          resources:
            requests:
              storage: 1Gi
          selector:
            matchLabels:
              app.kubernetes.io/name: prometheus-operator-alertmanager

  ## Passing the below configuration directives through the helm template
  ## engine leads to no substitution since the variables passed will be base64
  ## encoded directly hence we end up with `alertmanager.yaml` being invalid

  ## So let us disable the creation of this secret from the default charts
  ## and then create a new secret that replaces the
  ## alertmanager-prometheus-operator-alertmanager secret with new config
  ## read from a ConfigMap (metalk8s-alertmanager-config)

  # config: '__var_tojson__(alertmanager.spec.notification.config)'

    useExistingSecret: true

prometheusOperator:
  tlsProxy:
    enabled: false

  admissionWebhooks:
    enabled: false

  nodeSelector:
    node-role.kubernetes.io/infra: ''

  tolerations:
    - key: 'node-role.kubernetes.io/bootstrap'
      operator: 'Exists'
      effect: 'NoSchedule'
    - key: 'node-role.kubernetes.io/infra'
      operator: 'Exists'
      effect: 'NoSchedule'

  image:
    repository: '__image__(prometheus-operator)'

  configmapReloadImage:
    repository: '__image__(configmap-reload)'

  prometheusConfigReloaderImage:
    repository: '__image__(prometheus-config-reloader)'

  hyperkubeImage:
    repository: '__image__(hyperkube)'


prometheus:
  prometheusSpec:
    image:
      repository: '__image__(prometheus)'

    tolerations:
      - key: 'node-role.kubernetes.io/bootstrap'
        operator: 'Exists'
        effect: 'NoSchedule'
      - key: 'node-role.kubernetes.io/infra'
        operator: 'Exists'
        effect: 'NoSchedule'

    replicas: '__var__(prometheus.spec.deployment.replicas)'

    nodeSelector:
      node-role.kubernetes.io/infra: ''

    podAntiAffinity: 'soft'

    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: metalk8s-prometheus
          accessModes: ['ReadWriteOnce']
          resources:
            requests:
              storage: 10Gi
          selector:
            matchLabels:
              app.kubernetes.io/name: prometheus-operator-prometheus

    enableAdminAPI: '__var__(prometheus.spec.config.enable_admin_api)'

grafana:
  adminPassword: admin

  image:
    repository: '__image__(grafana)'
    tag: '6.7.4'

  sidecar:
    image: '__image__(k8s-sidecar):0.1.20'

  nodeSelector:
    node-role.kubernetes.io/infra: ''

  tolerations:
    - key: 'node-role.kubernetes.io/bootstrap'
      operator: 'Exists'
      effect: 'NoSchedule'
    - key: 'node-role.kubernetes.io/infra'
      operator: 'Exists'
      effect: 'NoSchedule'

  replicas: '__var__(grafana.spec.deployment.replicas)'


  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: nginx-control-plane
      nginx.ingress.kubernetes.io/rewrite-target: /$2
    path: /grafana(/|$)(.*)
    hosts:
      - null

  grafana.ini:
    server:
      root_url: '__escape__(https://{{ grains.metalk8s.control_plane_ip }}:8443/grafana)'
    analytics:
      reporting_enabled: false
      check_for_updates: false
    auth:
      oauth_auto_login: true
    auth.generic_oauth:
      enabled: true
      tls_skip_verify_insecure: true
      scopes: "openid profile email groups"
      client_id: "grafana-ui"
      client_secret: "4lqK98NcsWG5qBRHJUqYM1"
      auth_url: '__escape__(https://{{ grains.metalk8s.control_plane_ip }}:8443/oidc/auth)'
      token_url:  '__escape__(https://{{ grains.metalk8s.control_plane_ip }}:8443/oidc/token)'
      api_url: '__escape__(https://{{ grains.metalk8s.control_plane_ip }}:8443/oidc/userinfo)'
      role_attribute_path: contains(email, '{% endraw -%}{{ dex.spec.localuserstore.userlist[0]['email'] }}{%- raw %}') && 'Admin'

  testFramework:
    enabled: false


kube-state-metrics:
  image:
    repository: '__image__(kube-state-metrics)'

  nodeSelector:
    node-role.kubernetes.io/infra: ''

  tolerations:
    - key: 'node-role.kubernetes.io/bootstrap'
      operator: 'Exists'
      effect: 'NoSchedule'
    - key: 'node-role.kubernetes.io/infra'
      operator: 'Exists'
      effect: 'NoSchedule'


prometheus-node-exporter:
  image:
    repository: '__image__(node-exporter)'


kubeEtcd:
  service:
    port: 2381
    targetPort: 2381
